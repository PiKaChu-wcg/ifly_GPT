{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from utils.KnowledgeDict import KnowledgeDict\r\n",
    "from utils.Question import Question\r\n",
    "import pandas as pd\r\n",
    "from transformers import BertTokenizerFast\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "import torch.nn.utils.rnn as rnn_utils\r\n",
    "data_path=\"data/train_data.csv\"\r\n",
    "vocab_path=\"vocab/vocab.txt\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df=pd.read_csv(data_path)\r\n",
    "q_levl=3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def preprocess(df,q_level,batch_size):\r\n",
    "    KD=KnowledgeDict(3,df)\r\n",
    "    dict={}\r\n",
    "    tokenizer=BertTokenizerFast(vocab_file=vocab_path, sep_token=\"[SEP]\", pad_token=\"[PAD]\", cls_token=\"[CLS]\")\r\n",
    "    sep_id = tokenizer.sep_token_id\r\n",
    "    cls_id = tokenizer.cls_token_id\r\n",
    "    for _,item in df.iterrows():\r\n",
    "        if(item.TestQuestionID not in dict.keys()):\r\n",
    "            line=[cls_id]\r\n",
    "            if(item.type):\r\n",
    "                line+=tokenizer.encode(item.type[0],add_special_tokens=False)\r\n",
    "            line+=[sep_id]\r\n",
    "            if(item.Content):\r\n",
    "                line+=tokenizer.encode(item.Content,add_special_tokens=False)\r\n",
    "            line+=[sep_id]\r\n",
    "            if type(item.Analysis)==str:\r\n",
    "                line+=tokenizer.encode(item.Analysis,add_special_tokens=False)\r\n",
    "            line+=[sep_id]\r\n",
    "            if item.options:\r\n",
    "                line+=tokenizer.encode(item.options,add_special_tokens=False)\r\n",
    "            line+=[sep_id]\r\n",
    "            dict[item.TestQuestionID]={}\r\n",
    "            dict[item.TestQuestionID]['line']=line\r\n",
    "            dict[item.TestQuestionID]['q_Level']=item.q_Level-1\r\n",
    "        dict[item.TestQuestionID][item.k_Level]=KD.check_k(item.KnowledgeID)[1]\r\n",
    "    dataset=Question(dict,q_level) \r\n",
    "    def collate_fn(batch):\r\n",
    "        # print(\"batch:{}\".format(batch))\r\n",
    "        lines=[line[0] for line in batch]\r\n",
    "        t=[]\r\n",
    "        for k in range(1,len(batch[0])):\r\n",
    "            t.append(torch.cat([i[k].view(1,*i[k].shape) for i in batch]))\r\n",
    "        # print(f\"lines:{line}\")\r\n",
    "        input_ids = rnn_utils.pad_sequence(lines, batch_first=True, padding_value=0)\r\n",
    "        return input_ids,*t\r\n",
    "    dataloader=DataLoader(\r\n",
    "        dataset, batch_size=batch_size, \r\n",
    "        shuffle=True, \r\n",
    "        drop_last=True,\r\n",
    "        collate_fn=collate_fn\r\n",
    "    )  \r\n",
    "    return dataloader,KD"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "dataloader=preprocess(df,3,2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "next(iter(dataloader))[]\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-fd4a42f1ad6f>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-fd4a42f1ad6f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    next(iter(dataloader))[]\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "next(iter(dataloader))[1:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[27],\n",
       "         [26]]),\n",
       " tensor([[191],\n",
       "         [190]]),\n",
       " tensor([[1005],\n",
       "         [ 991]]),\n",
       " tensor([[0],\n",
       "         [0]]))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([  101,  1296,   102, 12797,  9085,  8179,  1158,  2456,  3144,  2945,\n",
       "          3198,  7313,  4638,  3297,  1825,  3315,  4638,  3175,  3791,  3221,\n",
       "           886,  4500,  8784, 12468,  8148,  3189,  3309,  2772,  3189,  3309,\n",
       "          3198,  7313,  3419,  2466,  4638,  2099,  5016,   706,   117,   809,\n",
       "           678,  6427,  1368,  2141,  4385,  4638,  1216,  5543,  3221,   168,\n",
       "          6134,  4850,  8020,  8021,   168,   134, 11203,   119,  8673,  8688,\n",
       "          8154,   113,   112,  9960,   118,  8116,   112,   117,   112,  9960,\n",
       "           118,  8155,   112,   117, 13260,  8179,  8619,   134,   112, 11624,\n",
       "          9785,  9165,   138,   146,   140,   112,   114,   102, 11203,   119,\n",
       "          8673,  8688,  8154,   113, 13260,  8179,  8619,   134, 11624,  9785,\n",
       "          9165,   138,   112,   146,   112,   140,   114,  8024,  2900,  2137,\n",
       "          3189,  3309,   809,  1921,   711,  1296,   855,  8024,  8673,  8688,\n",
       "          8154,  1377,  4500,   754,  4495,  2768,  3189,  3309,  5745,  1741,\n",
       "           102,  5815,  2533,  2792,  3300,   680,  9960,  2399,   127,  3299,\n",
       "          4638,  1921,  3144,   132,  5815,  2533,  2792,  3300,   680,  9960,\n",
       "          2399,   127,  3299,  4638,  2792,  3300,  3189,  3309,   132,  5815,\n",
       "          2533,  9960,  2399,   127,  3299,   118,   128,  3299,  7313,  4638,\n",
       "          3378,   671,  1921,  3189,  3309,   132, 11469,  8171,   102]),\n",
       " tensor([29]),\n",
       " tensor([73]),\n",
       " tensor([358]),\n",
       " tensor([2]))"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "40c4e17f077218d16613fe0a521debfb2207e39289331d3ad681e8733da961f0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}